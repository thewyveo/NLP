{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b022532d",
   "metadata": {},
   "source": [
    "Importing and Preprocessing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce56d272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence sentiment   topic\n",
      "0  The stadium was alive with the roar of the cro...  positive  sports\n",
      "1  That last-minute goal had me jumping out of my...  positive  sports\n",
      "2  I couldnâ€™t put the book down; it swept me into...  positive    book\n",
      "3  The story had its moments, though some parts f...   neutral    book\n",
      "4  I enjoyed the way the timelines shifted, even ...   neutral    book\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_data = pd.read_csv('sentiment-topic-test.tsv', sep='\\t')\n",
    "test_data.drop('sentence_id', axis=1, inplace=True)\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c4b01de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text   rating\n",
      "0  The Rock is destined to be the 21st Century 's...  0.50000\n",
      "1  The gorgeously elaborate continuation of `` Th...  0.44444\n",
      "2                     Effective but too-tepid biopic  0.50000\n",
      "3  If you sometimes like to go to the movies to h...  0.42708\n",
      "4  Emerges as something rare , an issue movie tha...  0.37500\n"
     ]
    }
   ],
   "source": [
    "sentences = pd.read_csv('stanfordSentimentTreebank\\datasetSentences.txt', sep='\\t')\n",
    "sentiments = pd.read_csv('stanfordSentimentTreebank\\sentiment_labels.txt', sep='|', engine='python')\n",
    "sentiments.columns = ['sentence_index', 'sentiment_value']\n",
    "\n",
    "train_data_stf = pd.merge(sentences, sentiments, on='sentence_index')\n",
    "train_data_stf = train_data_stf.rename(columns={'sentence': 'text', 'sentiment_value': 'rating'})\n",
    "train_data_stf.drop('sentence_index', axis=1, inplace=True)\n",
    "print(train_data_stf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7aed352b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rating distribution:\n",
      "rating\n",
      "1.0     6322\n",
      "2.0     4423\n",
      "3.0     8588\n",
      "4.0    16531\n",
      "5.0    64136\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Minimum count: 4423\n",
      "\n",
      "Balanced rating distribution:\n",
      "rating\n",
      "1.0    4423\n",
      "2.0    4423\n",
      "3.0    4423\n",
      "4.0    4423\n",
      "5.0    4423\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Original dataset size: 100000\n",
      "Balanced dataset size: 22115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12076\\3699505560.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  balanced_data = train_data.groupby('rating').apply(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"McAuley-Lab/Amazon-Reviews-2023\", \n",
    "    \"raw_review_Movies_and_TV\", \n",
    "    split=\"full[:100000]\", \n",
    "    trust_remote_code=True\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(dataset)  # Convert to pandas DataFrame\n",
    "train_data = df[['rating', 'text']]\n",
    "# train_data = train_data[train_data['text'].str.split().str.len() <= 30]\n",
    "\n",
    "# Check original distribution\n",
    "print(\"Original rating distribution:\")\n",
    "print(train_data['rating'].value_counts().sort_index())\n",
    "\n",
    "# Find the minimum count across all rating classes\n",
    "min_count = train_data['rating'].value_counts().min()\n",
    "print(f\"\\nMinimum count: {min_count}\")\n",
    "\n",
    "# Balance the classes by sampling equal amounts from each rating\n",
    "balanced_data = train_data.groupby('rating').apply(\n",
    "    lambda x: x.sample(n=min_count, random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nBalanced rating distribution:\")\n",
    "print(balanced_data['rating'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nOriginal dataset size: {len(train_data)}\")\n",
    "print(f\"Balanced dataset size: {len(balanced_data)}\")\n",
    "\n",
    "# Use balanced_data for your training\n",
    "train_data_amazon = balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "deaa331a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>The same exact thing over and over. Nothing bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I turned it off after 10 minutes because it wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Wow, I was SO EXCITED when this movie hit Amaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Hollywood style attempt at recreating the horr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>The Office is one of my very favorite shows, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                               text\n",
       "0     1.0  The same exact thing over and over. Nothing bu...\n",
       "1     1.0  I turned it off after 10 minutes because it wa...\n",
       "2     1.0  Wow, I was SO EXCITED when this movie hit Amaz...\n",
       "3     1.0  Hollywood style attempt at recreating the horr...\n",
       "4     1.0  The Office is one of my very favorite shows, s..."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c4e933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       rating                                               text\n",
      "5         1.0         Don't be fooled, there is no mystery here.\n",
      "6         1.0                                         Too boring\n",
      "7         1.0  This is a scam.  Got an email for a free digit...\n",
      "8         1.0  Another shock jock trying to pass off as humor...\n",
      "9         1.0           Sorry I even watched 15 minutes of this.\n",
      "...       ...                                                ...\n",
      "33965     5.0                                    A real snooze .\n",
      "33966     5.0                                     No surprises .\n",
      "33967     5.0  We 've seen the hippie-turned-yuppie plot befo...\n",
      "33968     5.0  Her fans walked out muttering words like `` ho...\n",
      "33969     5.0                                In this case zero .\n",
      "\n",
      "[33965 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data_stf['rating'] = (train_data_stf['rating'] * 5).clip(1, 5).round()\n",
    "train_data_combined = pd.concat([train_data_amazon, train_data_stf], ignore_index=True)\n",
    "\n",
    "print(train_data_combined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78944c8a",
   "metadata": {},
   "source": [
    "Analysis with Multinominal Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce144ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.83      0.67         6\n",
      "     neutral       0.00      0.00      0.00         6\n",
      "    positive       0.44      0.67      0.53         6\n",
      "\n",
      "    accuracy                           0.50        18\n",
      "   macro avg       0.33      0.50      0.40        18\n",
      "weighted avg       0.33      0.50      0.40        18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\staff\\NLP\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Lenovo\\staff\\NLP\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Lenovo\\staff\\NLP\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def rating_to_sentiment(rating):\n",
    "    if rating >= 3.0:\n",
    "        return 'positive'\n",
    "    elif rating <= 2.0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=3)\n",
    "\n",
    "train_data_combined['sentiment'] = train_data_combined['rating'].apply(rating_to_sentiment)\n",
    "X_train_text = train_data_combined['text']\n",
    "y_train_labels = train_data_combined['sentiment']\n",
    "\n",
    "# Fit vectorizer on training text and transform both datasets\n",
    "X_train_vec = vectorizer.fit_transform(X_train_text)\n",
    "X_test_vec = vectorizer.transform(test_data['sentence'])  # Use 'sentence' column from test data\n",
    "\n",
    "# Train the model\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vec, y_train_labels)\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "y_test_actual = test_data['sentiment']\n",
    "\n",
    "target_names = ['negative', 'neutral', 'positive']\n",
    "print(classification_report(y_test_actual, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b2e0f1",
   "metadata": {},
   "source": [
    "Analysis with VADER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463cacf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "vader_model = SentimentIntensityAnalyzer()\n",
    "pos = set()\n",
    "\n",
    "def run_vader(sentence, lemmatize=True, parts_of_speech_to_consider=pos):\n",
    "    \"\"\"\n",
    "    Run VADER on a sentence and return the scores.\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    input_to_vader = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            to_add = token.text\n",
    "\n",
    "            if lemmatize:\n",
    "                to_add = token.lemma_\n",
    "\n",
    "                if to_add == '-PRON-': \n",
    "                    to_add = token.text\n",
    "\n",
    "            if parts_of_speech_to_consider:\n",
    "                if token.pos_ in parts_of_speech_to_consider:\n",
    "                    input_to_vader.append(to_add) \n",
    "            else:\n",
    "                input_to_vader.append(to_add)\n",
    "\n",
    "    scores = vader_model.polarity_scores(' '.join(input_to_vader))\n",
    "    return scores\n",
    "\n",
    "def vader_output_to_label(vader_output):\n",
    "    \"\"\"\n",
    "    Convert VADER output to a label.\n",
    "    \"\"\"\n",
    "    compound = vader_output['compound']\n",
    "    \n",
    "    if compound > 0:\n",
    "        return 'positive'\n",
    "    elif compound < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "    \n",
    "tweets = []\n",
    "all_vader_output = []\n",
    "gold = []\n",
    "\n",
    "for id_, tweet_info in my_tweets.items():\n",
    "    the_tweet = tweet_info['text_of_tweet']\n",
    "    vader_output = run_vader(tweet_info['text_of_tweet']) # run vader\n",
    "    vader_label = vader_output_to_label(vader_output) # convert vader output to category\n",
    "    \n",
    "    tweets.append(the_tweet)\n",
    "    all_vader_output.append(vader_label)\n",
    "    gold.append(tweet_info['sentiment_label'])\n",
    "    \n",
    "\n",
    "print(tweets[2])\n",
    "print(f'prediction: {all_vader_output[2]}, gold: {gold[2]}')\n",
    "\n",
    "print(classification_report(gold, all_vader_output))\n",
    "print(confusion_matrix(gold, all_vader_output))\n",
    "print(f'accuracy: {accuracy_score(gold, all_vader_output)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
