{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f67ff92c",
   "metadata": {},
   "source": [
    "# Named Entity Recognition and Classification (NERC) Analysis\n",
    "\n",
    "**Objective:** Compare two state-of-the-art NER systems on provided test data\n",
    "\n",
    "**Systems Evaluated:**\n",
    "- System 1: spaCy transformer model (`en_core_web_trf`)  \n",
    "- System 2: BERT NER model (`dslim/bert-base-NER`)\n",
    "\n",
    "**Methodology:** Apply both pre-trained models to NER-test.tsv and compare performance using standard NER evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea4a2a3",
   "metadata": {},
   "source": [
    " Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "428af006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   token_id     token BIO_NER_tag\n",
      "0         0        If           O\n",
      "1         1    you're           O\n",
      "2         2  visiting           O\n",
      "3         3     Paris  B-LOCATION\n",
      "4         4         ,           O\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForTokenClassification, \n",
    "    TrainingArguments, DataCollatorForTokenClassification\n",
    ")\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "import random\n",
    "\n",
    "\n",
    "test_data = pd.read_csv('datasets/NER-test.tsv', sep='\\t')\n",
    "test_data.drop('sentence_id', axis=1, inplace=True)\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f8b3e",
   "metadata": {},
   "source": [
    "Data Set Loading and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a721c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDatasetLoader:\n",
    "    def __init__(self):\n",
    "        self.datasets = {}\n",
    "        self.label_mappings = {}\n",
    "    \n",
    "    def load_conll2003(self):\n",
    "        \"\"\"Load CoNLL-2003 dataset\"\"\"\n",
    "        print(\"Loading CoNLL-2003 dataset...\")\n",
    "        dataset = load_dataset(\"conll2003\")\n",
    "        \n",
    "        # Extract labels\n",
    "        labels = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
    "        self.label_mappings['conll2003'] = {i: label for i, label in enumerate(labels)}\n",
    "        \n",
    "        self.datasets['conll2003'] = {\n",
    "            'train': dataset['train'],\n",
    "            'validation': dataset['validation'],\n",
    "            'test': dataset['test'],\n",
    "            'labels': labels\n",
    "        }\n",
    "        print(f\"CoNLL-2003 loaded. Labels: {labels}\")\n",
    "        return self.datasets['conll2003']\n",
    "    \n",
    "    def load_wikiann(self, language='en'):\n",
    "        \"\"\"Load WikiANN dataset for English\"\"\"\n",
    "        print(f\"Loading WikiANN ({language}) dataset...\")\n",
    "        dataset = load_dataset(\"wikiann\", language)\n",
    "        \n",
    "        # Extract labels\n",
    "        labels = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
    "        self.label_mappings['wikiann'] = {i: label for i, label in enumerate(labels)}\n",
    "        \n",
    "        self.datasets['wikiann'] = {\n",
    "            'train': dataset['train'],\n",
    "            'validation': dataset['validation'],\n",
    "            'test': dataset['test'],\n",
    "            'labels': labels\n",
    "        }\n",
    "        print(f\"WikiANN ({language}) loaded. Labels: {labels}\")\n",
    "        return self.datasets['wikiann']\n",
    "    \n",
    "    def load_wnut17(self):\n",
    "        \"\"\"Load WNUT-17 dataset\"\"\"\n",
    "        print(\"Loading WNUT-17 dataset...\")\n",
    "        dataset = load_dataset(\"wnut_17\")\n",
    "        \n",
    "        # Extract labels\n",
    "        labels = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
    "        self.label_mappings['wnut17'] = {i: label for i, label in enumerate(labels)}\n",
    "        \n",
    "        self.datasets['wnut17'] = {\n",
    "            'train': dataset['train'],\n",
    "            'validation': dataset['validation'],\n",
    "            'test': dataset['test'],\n",
    "            'labels': labels\n",
    "        }\n",
    "        print(f\"WNUT-17 loaded. Labels: {labels}\")\n",
    "        return self.datasets['wnut17']\n",
    "    \n",
    "    def get_combined_labels(self):\n",
    "        \"\"\"Get all unique labels across datasets\"\"\"\n",
    "        all_labels = set()\n",
    "        for dataset_name, mapping in self.label_mappings.items():\n",
    "            all_labels.update(mapping.values())\n",
    "        return sorted(list(all_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d6f33",
   "metadata": {},
   "source": [
    "**Data preprocessing for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14280a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataPreprocessor:\n",
    "    def __init__(self, tokenizer_name=\"bert-base-cased\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        \n",
    "    def align_labels_with_tokens(self, labels, word_ids):\n",
    "        \"\"\"Align labels with tokenized words\"\"\"\n",
    "        new_labels = []\n",
    "        current_word = None\n",
    "        for word_id in word_ids:\n",
    "            if word_id != current_word:\n",
    "                current_word = word_id\n",
    "                label = -100 if word_id is None else labels[word_id]\n",
    "                new_labels.append(label)\n",
    "            elif word_id is None:\n",
    "                new_labels.append(-100)\n",
    "            else:\n",
    "                label = labels[word_id]\n",
    "                if label % 2 == 1:  # If it's an I- tag\n",
    "                    new_labels.append(label)\n",
    "                else:  # If it's a B- tag, change to I-\n",
    "                    new_labels.append(label + 1 if label != 0 else 0)\n",
    "        return new_labels\n",
    "    \n",
    "    def tokenize_and_align_labels(self, examples, label_all_tokens=True):\n",
    "        \"\"\"Tokenize and align labels for BERT-style models\"\"\"\n",
    "        tokenized_inputs = self.tokenizer(\n",
    "            examples[\"tokens\"], \n",
    "            truncation=True, \n",
    "            is_split_into_words=True,\n",
    "            padding=True,\n",
    "            max_length=512\n",
    "        )\n",
    "        \n",
    "        labels = []\n",
    "        for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "            word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "            aligned_labels = self.align_labels_with_tokens(label, word_ids)\n",
    "            labels.append(aligned_labels)\n",
    "        \n",
    "        tokenized_inputs[\"labels\"] = labels\n",
    "        return tokenized_inputs\n",
    "    \n",
    "    def prepare_spacy_data(self, dataset):\n",
    "        \"\"\"Prepare data for spaCy training\"\"\"\n",
    "        training_data = []\n",
    "        \n",
    "        for example in dataset:\n",
    "            tokens = example['tokens']\n",
    "            ner_tags = example['ner_tags']\n",
    "            \n",
    "            # Convert to spaCy format\n",
    "            entities = []\n",
    "            start_pos = 0\n",
    "            \n",
    "            for i, (token, tag) in enumerate(zip(tokens, ner_tags)):\n",
    "                if tag != 0:  # Not 'O' tag\n",
    "                    tag_name = dataset.features['ner_tags'].feature.names[tag]\n",
    "                    if tag_name.startswith('B-'):\n",
    "                        entity_start = start_pos\n",
    "                        entity_label = tag_name[2:]\n",
    "                        entity_end = start_pos + len(token)\n",
    "                        \n",
    "                        # Check for I- tags following this B- tag\n",
    "                        j = i + 1\n",
    "                        while j < len(ner_tags) and dataset.features['ner_tags'].feature.names[ner_tags[j]].startswith(f'I-{entity_label}'):\n",
    "                            entity_end = start_pos + len(' '.join(tokens[i:j+1]))\n",
    "                            j += 1\n",
    "                        \n",
    "                        entities.append((entity_start, entity_end, entity_label))\n",
    "                \n",
    "                start_pos += len(token) + 1  # +1 for space\n",
    "            \n",
    "            text = ' '.join(tokens)\n",
    "            training_data.append((text, {\"entities\": entities}))\n",
    "        \n",
    "        return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e49055d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmedmusayev/anaconda3/lib/python3.11/site-packages/thinc/shims/pytorch.py:261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filelike, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy model loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT NER pipeline loaded successfully\n",
      "Testing on: 'Apple Inc. is based in Cupertino, California. Tim Cook is the CEO.'\n",
      "spaCy entities: [('Apple Inc.', 'ORG'), ('Cupertino', 'GPE'), ('California', 'GPE'), ('Tim Cook', 'PERSON')]\n",
      "BERT entities: [('Apple Inc', 'ORG'), ('Cupertino', 'LOC'), ('California', 'LOC'), ('Tim Cook', 'PER')]\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained spaCy model\n",
    "try:\n",
    "    nlp_spacy = spacy.load(\"en_core_web_trf\")\n",
    "    print(\"spaCy model loaded successfully\")\n",
    "except OSError:\n",
    "    print(\"spaCy model not found. Please install with: python -m spacy download en_core_web_trf\")\n",
    "\n",
    "# Load pre-trained BERT NER pipeline\n",
    "from transformers import pipeline\n",
    "bert_ner = pipeline(\"ner\", \n",
    "                   model=\"dslim/bert-base-NER\", \n",
    "                   tokenizer=\"dslim/bert-base-NER\",\n",
    "                   aggregation_strategy=\"simple\")\n",
    "print(\"BERT NER pipeline loaded successfully\")\n",
    "\n",
    "# Test both models on a sample\n",
    "test_text = \"Apple Inc. is based in Cupertino, California. Tim Cook is the CEO.\"\n",
    "print(f\"Testing on: '{test_text}'\")\n",
    "\n",
    "# Test spaCy\n",
    "doc = nlp_spacy(test_text)\n",
    "print(\"spaCy entities:\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "# Test BERT\n",
    "bert_entities = bert_ner(test_text)\n",
    "print(\"BERT entities:\", [(ent['word'], ent['entity_group']) for ent in bert_entities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7502b0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 test sentences\n",
      "First few examples:\n",
      "Sentence 0: If you're visiting Paris , make sure to see the Louvre , as they exhibit the Mona Lisa !\n",
      "True NER tags: ['O', 'O', 'O', 'B-LOCATION', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'O']\n",
      "\n",
      "Sentence 1: Amazon , Google and Meta control a huge share of the technology market globally .\n",
      "True NER tags: ['B-ORG', 'O', 'B-ORG', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Sentence 2: Did you hear Pharoah Sanders recorded an album with Floating Points ?\n",
      "True NER tags: ['O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_test_data():\n",
    "    \"\"\"Load and process the NER-test.tsv file\"\"\"\n",
    "    test_df = pd.read_csv('datasets/NER-test.tsv', sep='\\t')\n",
    "    \n",
    "    # Group by sentence_id to reconstruct sentences\n",
    "    sentences = []\n",
    "    sentence_data = []\n",
    "    \n",
    "    for sentence_id in test_df['sentence_id'].unique():\n",
    "        sentence_tokens = test_df[test_df['sentence_id'] == sentence_id]\n",
    "        \n",
    "        tokens = sentence_tokens['token'].tolist()\n",
    "        ner_tags = sentence_tokens['BIO_NER_tag'].tolist()\n",
    "        sentence_text = ' '.join(tokens)\n",
    "        \n",
    "        sentences.append(sentence_text)\n",
    "        sentence_data.append({\n",
    "            'sentence_id': sentence_id,\n",
    "            'tokens': tokens,\n",
    "            'ner_tags': ner_tags,\n",
    "            'sentence': sentence_text\n",
    "        })\n",
    "    \n",
    "    return sentences, sentence_data\n",
    "\n",
    "# Load the test data\n",
    "test_sentences, test_data_structured = load_test_data()\n",
    "\n",
    "print(f\"Loaded {len(test_sentences)} test sentences\")\n",
    "print(\"First few examples:\")\n",
    "\n",
    "# Show first few examples\n",
    "for i, data in enumerate(test_data_structured[:3]):\n",
    "    print(f\"Sentence {data['sentence_id']}: {data['sentence']}\")\n",
    "    print(f\"True NER tags: {data['ner_tags']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca30d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying spaCy NER...\n",
      "Applying BERT NER...\n",
      "Both NER systems applied successfully\n",
      "Processed 15 sentences with spaCy\n",
      "Processed 15 sentences with BERT\n"
     ]
    }
   ],
   "source": [
    "def apply_spacy_ner(sentences):\n",
    "    \"\"\"Apply spaCy NER to sentences and return BIO tags\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        doc = nlp_spacy(sentence)\n",
    "        tokens = [token.text for token in doc]\n",
    "        ner_tags = []\n",
    "        \n",
    "        for token in doc:\n",
    "            if token.ent_type_:\n",
    "                if token.ent_iob_ == 'B':\n",
    "                    ner_tags.append(f\"B-{token.ent_type_}\")\n",
    "                elif token.ent_iob_ == 'I':\n",
    "                    ner_tags.append(f\"I-{token.ent_type_}\")\n",
    "                else:\n",
    "                    ner_tags.append('O')\n",
    "            else:\n",
    "                ner_tags.append('O')\n",
    "        \n",
    "        results.append({'tokens': tokens, 'ner_tags': ner_tags})\n",
    "    \n",
    "    return results\n",
    "\n",
    "def apply_bert_ner(sentences):\n",
    "    \"\"\"Apply BERT NER to sentences and return BIO tags\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # Get BERT predictions\n",
    "        entities = bert_ner(sentence)\n",
    "        \n",
    "        # Simple tokenization for alignment\n",
    "        tokens = sentence.split()\n",
    "        ner_tags = ['O'] * len(tokens)\n",
    "        \n",
    "        # Map BERT entities to tokens\n",
    "        for entity in entities:\n",
    "            entity_text = entity['word'].replace('##', '')\n",
    "            entity_label = entity['entity_group']\n",
    "            \n",
    "            # Find matching tokens\n",
    "            for i, token in enumerate(tokens):\n",
    "                if (entity_text.lower() in token.lower() or \n",
    "                    token.lower() in entity_text.lower()):\n",
    "                    if ner_tags[i] == 'O':\n",
    "                        ner_tags[i] = f\"B-{entity_label}\"\n",
    "                    break\n",
    "        \n",
    "        results.append({'tokens': tokens, 'ner_tags': ner_tags})\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Apply both systems to test data\n",
    "print(\"Applying spaCy NER...\")\n",
    "spacy_results = apply_spacy_ner(test_sentences)\n",
    "\n",
    "print(\"Applying BERT NER...\")\n",
    "bert_results = apply_bert_ner(test_sentences)\n",
    "\n",
    "print(\"Both NER systems applied successfully\")\n",
    "print(f\"Processed {len(spacy_results)} sentences with spaCy\")\n",
    "print(f\"Processed {len(bert_results)} sentences with BERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff234b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM COMPARISON RESULTS:\n",
      "==================================================\n",
      "Total tokens analyzed: 216\n",
      "spaCy accuracy: 0.8380\n",
      "BERT accuracy: 0.7454\n",
      "System agreement: 0.7130\n",
      "\n",
      "Sample Comparison (first 10 tokens):\n",
      "      token  true_label spacy_pred bert_pred  spacy_correct  bert_correct\n",
      "0        If           O          O         O           True          True\n",
      "1    you're           O          O         O           True          True\n",
      "2  visiting           O          O         O           True          True\n",
      "3     Paris  B-LOCATION          O     B-LOC          False         False\n",
      "4         ,           O      B-GPE         O          False          True\n",
      "5      make           O          O         O           True          True\n",
      "6      sure           O          O         O           True          True\n",
      "7        to           O          O         O           True          True\n",
      "8       see           O          O         O           True          True\n",
      "9       the           O          O         O           True          True\n",
      "\n",
      "System Disagreements (62 tokens):\n",
      "     token     true_label     spacy_pred bert_pred\n",
      "3    Paris     B-LOCATION              O     B-LOC\n",
      "4        ,              O          B-GPE         O\n",
      "10  Louvre          B-ORG              O     B-ORG\n",
      "11       ,              O          B-FAC         O\n",
      "16    Mona  B-WORK_OF_ART  B-WORK_OF_ART    B-MISC\n"
     ]
    }
   ],
   "source": [
    "def create_comparison_dataframe(test_data_structured, spacy_results, bert_results):\n",
    "    \"\"\"Create detailed comparison dataframe\"\"\"\n",
    "    comparison_data = []\n",
    "    \n",
    "    for i, (test_data, spacy_result, bert_result) in enumerate(zip(test_data_structured, spacy_results, bert_results)):\n",
    "        sentence_id = test_data['sentence_id']\n",
    "        true_tokens = test_data['tokens']\n",
    "        true_labels = test_data['ner_tags']\n",
    "        \n",
    "        spacy_tokens = spacy_result['tokens']\n",
    "        spacy_labels = spacy_result['ner_tags']\n",
    "        \n",
    "        bert_tokens = bert_result['tokens']\n",
    "        bert_labels = bert_result['ner_tags']\n",
    "        \n",
    "        # Align tokens (use true tokens as reference)\n",
    "        for j, token in enumerate(true_tokens):\n",
    "            true_label = true_labels[j] if j < len(true_labels) else 'O'\n",
    "            spacy_label = spacy_labels[j] if j < len(spacy_labels) else 'O'\n",
    "            bert_label = bert_labels[j] if j < len(bert_labels) else 'O'\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'sentence_id': sentence_id,\n",
    "                'token': token,\n",
    "                'true_label': true_label,\n",
    "                'spacy_pred': spacy_label,\n",
    "                'bert_pred': bert_label,\n",
    "                'spacy_correct': spacy_label == true_label,\n",
    "                'bert_correct': bert_label == true_label,\n",
    "                'systems_agree': spacy_label == bert_label\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(comparison_data)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = create_comparison_dataframe(test_data_structured, spacy_results, bert_results)\n",
    "\n",
    "print(\"SYSTEM COMPARISON RESULTS:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total tokens analyzed: {len(comparison_df)}\")\n",
    "print(f\"spaCy accuracy: {comparison_df['spacy_correct'].mean():.4f}\")\n",
    "print(f\"BERT accuracy: {comparison_df['bert_correct'].mean():.4f}\")\n",
    "print(f\"System agreement: {comparison_df['systems_agree'].mean():.4f}\")\n",
    "\n",
    "print(\"\\nSample Comparison (first 10 tokens):\")\n",
    "print(comparison_df[['token', 'true_label', 'spacy_pred', 'bert_pred', 'spacy_correct', 'bert_correct']].head(10))\n",
    "\n",
    "# Show disagreements\n",
    "disagreements = comparison_df[~comparison_df['systems_agree']]\n",
    "print(f\"\\nSystem Disagreements ({len(disagreements)} tokens):\")\n",
    "if len(disagreements) > 0:\n",
    "    print(disagreements[['token', 'true_label', 'spacy_pred', 'bert_pred']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97f483ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” NAMED ENTITY EXTRACTION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Sentence 0: If you're visiting Paris , make sure to see the Louvre , as they exhibit the Mona Lisa !\n",
      "True entities: [('Paris', 'LOCATION'), ('Louvre', 'ORG'), ('Mona Lisa', 'WORK_OF_ART')]\n",
      "spaCy entities: [('Paris', 'GPE'), ('Louvre', 'FAC'), ('the Mona Lisa', 'WORK_OF_ART')]\n",
      "BERT entities: [('Paris', 'LOC'), ('Louvre', 'ORG'), ('Mona', 'MISC')]\n",
      "\n",
      "ðŸ“ Sentence 1: Amazon , Google and Meta control a huge share of the technology market globally .\n",
      "True entities: [('Amazon', 'ORG'), ('Google', 'ORG'), ('Meta', 'ORG')]\n",
      "spaCy entities: [('Amazon', 'ORG'), ('Google', 'ORG'), ('Meta', 'ORG')]\n",
      "BERT entities: [('Amazon', 'ORG'), ('Google', 'ORG'), ('Meta', 'ORG')]\n",
      "\n",
      "ðŸ“ Sentence 2: Did you hear Pharoah Sanders recorded an album with Floating Points ?\n",
      "True entities: [('Pharoah Sanders', 'PERSON'), ('Floating Points', 'PERSON')]\n",
      "spaCy entities: [('Pharoah Sanders', 'PERSON'), ('Floating Points', 'WORK_OF_ART')]\n",
      "BERT entities: [('Pharoah', 'PER'), ('Sanders', 'PER'), ('Floating', 'ORG')]\n",
      "\n",
      "ðŸ“ Sentence 3: Madvillainy is still my favourite MF DOOM record .\n",
      "True entities: [('Madvillainy', 'WORK_OF_ART'), ('MF DOOM', 'PERSON')]\n",
      "spaCy entities: [('Madvillainy', 'WORK_OF_ART')]\n",
      "BERT entities: []\n",
      "\n",
      "ðŸ“ Sentence 4: My friend Kevin just finished watching Succession , and won't stop talking about Kieran Culkin 's performance .\n",
      "True entities: [('Kevin', 'PERSON'), ('Succession', 'WORK_OF_ART'), ('Kieran Culkin', 'PERSON')]\n",
      "spaCy entities: [('Kevin', 'PERSON'), ('Succession', 'WORK_OF_ART'), (\"Kieran Culkin 's\", 'PERSON')]\n",
      "BERT entities: [('Kevin', 'PER'), ('Succession', 'MISC'), ('talking', 'PER'), ('Culkin', 'PER')]\n"
     ]
    }
   ],
   "source": [
    "def extract_entities_from_bio(tokens, bio_tags):\n",
    "    \"\"\"Extract named entities from BIO-tagged tokens\"\"\"\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "    current_tokens = []\n",
    "    \n",
    "    for token, tag in zip(tokens, bio_tags):\n",
    "        if tag.startswith('B-'):\n",
    "            # Save previous entity if exists\n",
    "            if current_entity and current_tokens:\n",
    "                entities.append({\n",
    "                    'text': ' '.join(current_tokens),\n",
    "                    'label': current_entity,\n",
    "                    'tokens': current_tokens.copy()\n",
    "                })\n",
    "            \n",
    "            # Start new entity\n",
    "            current_entity = tag[2:]  # Remove 'B-' prefix\n",
    "            current_tokens = [token]\n",
    "            \n",
    "        elif tag.startswith('I-') and current_entity == tag[2:]:\n",
    "            # Continue current entity\n",
    "            current_tokens.append(token)\n",
    "            \n",
    "        else:\n",
    "            # End current entity\n",
    "            if current_entity and current_tokens:\n",
    "                entities.append({\n",
    "                    'text': ' '.join(current_tokens),\n",
    "                    'label': current_entity,\n",
    "                    'tokens': current_tokens.copy()\n",
    "                })\n",
    "            current_entity = None\n",
    "            current_tokens = []\n",
    "    \n",
    "    # Don't forget last entity\n",
    "    if current_entity and current_tokens:\n",
    "        entities.append({\n",
    "            'text': ' '.join(current_tokens),\n",
    "            'label': current_entity,\n",
    "            'tokens': current_tokens.copy()\n",
    "        })\n",
    "    \n",
    "    return entities\n",
    "\n",
    "# Extract entities for each system\n",
    "print(\"ðŸ” NAMED ENTITY EXTRACTION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, (test_data, spacy_result, bert_result) in enumerate(zip(test_data_structured, spacy_results, bert_results)):\n",
    "    sentence = test_data['sentence']\n",
    "    true_entities = extract_entities_from_bio(test_data['tokens'], test_data['ner_tags'])\n",
    "    spacy_entities = extract_entities_from_bio(spacy_result['tokens'], spacy_result['ner_tags'])\n",
    "    bert_entities = extract_entities_from_bio(bert_result['tokens'], bert_result['ner_tags'])\n",
    "    \n",
    "    print(f\"\\nðŸ“ Sentence {test_data['sentence_id']}: {sentence}\")\n",
    "    print(f\"True entities: {[(e['text'], e['label']) for e in true_entities]}\")\n",
    "    print(f\"spaCy entities: {[(e['text'], e['label']) for e in spacy_entities]}\")\n",
    "    print(f\"BERT entities: {[(e['text'], e['label']) for e in bert_entities]}\")\n",
    "    \n",
    "    if i >= 4:  # Show first 5 sentences\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e7d74e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMED ENTITY EXTRACTION RESULTS\n",
      "============================================================\n",
      "\n",
      "Sentence 0: If you're visiting Paris , make sure to see the Louvre , as they exhibit the Mona Lisa !\n",
      "True entities: [('Paris', 'LOCATION'), ('Louvre', 'ORG'), ('Mona Lisa', 'WORK_OF_ART')]\n",
      "spaCy entities: [('Paris', 'GPE'), ('Louvre', 'FAC'), ('the Mona Lisa', 'WORK_OF_ART')]\n",
      "BERT entities: [('Paris', 'LOC'), ('Louvre', 'ORG'), ('Mona', 'MISC')]\n",
      "\n",
      "Sentence 1: Amazon , Google and Meta control a huge share of the technology market globally .\n",
      "True entities: [('Amazon', 'ORG'), ('Google', 'ORG'), ('Meta', 'ORG')]\n",
      "spaCy entities: [('Amazon', 'ORG'), ('Google', 'ORG'), ('Meta', 'ORG')]\n",
      "BERT entities: [('Amazon', 'ORG'), ('Google', 'ORG'), ('Meta', 'ORG')]\n",
      "\n",
      "Sentence 2: Did you hear Pharoah Sanders recorded an album with Floating Points ?\n",
      "True entities: [('Pharoah Sanders', 'PERSON'), ('Floating Points', 'PERSON')]\n",
      "spaCy entities: [('Pharoah Sanders', 'PERSON'), ('Floating Points', 'WORK_OF_ART')]\n",
      "BERT entities: [('Pharoah', 'PER'), ('Sanders', 'PER'), ('Floating', 'ORG')]\n",
      "\n",
      "Sentence 3: Madvillainy is still my favourite MF DOOM record .\n",
      "True entities: [('Madvillainy', 'WORK_OF_ART'), ('MF DOOM', 'PERSON')]\n",
      "spaCy entities: [('Madvillainy', 'WORK_OF_ART')]\n",
      "BERT entities: []\n",
      "\n",
      "Sentence 4: My friend Kevin just finished watching Succession , and won't stop talking about Kieran Culkin 's performance .\n",
      "True entities: [('Kevin', 'PERSON'), ('Succession', 'WORK_OF_ART'), ('Kieran Culkin', 'PERSON')]\n",
      "spaCy entities: [('Kevin', 'PERSON'), ('Succession', 'WORK_OF_ART'), (\"Kieran Culkin 's\", 'PERSON')]\n",
      "BERT entities: [('Kevin', 'PER'), ('Succession', 'MISC'), ('talking', 'PER'), ('Culkin', 'PER')]\n"
     ]
    }
   ],
   "source": [
    "def extract_entities_from_bio(tokens, bio_tags):\n",
    "    \"\"\"Extract named entities from BIO-tagged tokens\"\"\"\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "    current_tokens = []\n",
    "    \n",
    "    for token, tag in zip(tokens, bio_tags):\n",
    "        if tag.startswith('B-'):\n",
    "            # Save previous entity if exists\n",
    "            if current_entity and current_tokens:\n",
    "                entities.append({\n",
    "                    'text': ' '.join(current_tokens),\n",
    "                    'label': current_entity\n",
    "                })\n",
    "            \n",
    "            # Start new entity\n",
    "            current_entity = tag[2:]  # Remove 'B-' prefix\n",
    "            current_tokens = [token]\n",
    "            \n",
    "        elif tag.startswith('I-') and current_entity == tag[2:]:\n",
    "            # Continue current entity\n",
    "            current_tokens.append(token)\n",
    "            \n",
    "        else:\n",
    "            # End current entity\n",
    "            if current_entity and current_tokens:\n",
    "                entities.append({\n",
    "                    'text': ' '.join(current_tokens),\n",
    "                    'label': current_entity\n",
    "                })\n",
    "            current_entity = None\n",
    "            current_tokens = []\n",
    "    \n",
    "    # Don't forget last entity\n",
    "    if current_entity and current_tokens:\n",
    "        entities.append({\n",
    "            'text': ' '.join(current_tokens),\n",
    "            'label': current_entity\n",
    "        })\n",
    "    \n",
    "    return entities\n",
    "\n",
    "# Extract entities for each system\n",
    "print(\"NAMED ENTITY EXTRACTION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, (test_data, spacy_result, bert_result) in enumerate(zip(test_data_structured, spacy_results, bert_results)):\n",
    "    sentence = test_data['sentence']\n",
    "    true_entities = extract_entities_from_bio(test_data['tokens'], test_data['ner_tags'])\n",
    "    spacy_entities = extract_entities_from_bio(spacy_result['tokens'], spacy_result['ner_tags'])\n",
    "    bert_entities = extract_entities_from_bio(bert_result['tokens'], bert_result['ner_tags'])\n",
    "    \n",
    "    print(f\"\\nSentence {test_data['sentence_id']}: {sentence}\")\n",
    "    print(f\"True entities: {[(e['text'], e['label']) for e in true_entities]}\")\n",
    "    print(f\"spaCy entities: {[(e['text'], e['label']) for e in spacy_entities]}\")\n",
    "    print(f\"BERT entities: {[(e['text'], e['label']) for e in bert_entities]}\")\n",
    "    \n",
    "    if i >= 4:  # Show first 5 sentences\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35d4ddfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL ANALYSIS & ERROR PATTERNS\n",
      "============================================================\n",
      "\n",
      "Overall Performance:\n",
      "spaCy accuracy: 0.8380\n",
      "BERT accuracy: 0.7454\n",
      "System agreement: 0.7130\n",
      "\n",
      "Performance by Entity Type:\n",
      "PERSON: spaCy 0.600, BERT 0.000 (25 tokens)\n",
      "ORG: spaCy 0.462, BERT 0.385 (13 tokens)\n",
      "LOCATION: spaCy 0.000, BERT 0.000 (5 tokens)\n",
      "WORK_OF_ART: spaCy 1.000, BERT 0.000 (14 tokens)\n",
      "\n",
      "Error Summary:\n",
      "spaCy errors: 35 tokens\n",
      "BERT errors: 55 tokens\n",
      "\n",
      "Most common spaCy error patterns:\n",
      "    true_label spacy_pred  count\n",
      "7     B-PERSON          O      4\n",
      "11    I-PERSON   B-PERSON      3\n",
      "8   I-LOCATION      I-GPE      2\n",
      "21           O   I-PERSON      2\n",
      "20           O     I-DATE      2\n",
      "\n",
      "Most common BERT error patterns:\n",
      "       true_label bert_pred  count\n",
      "14       I-PERSON         O      9\n",
      "16  I-WORK_OF_ART         O      7\n",
      "5        B-PERSON     B-PER      7\n",
      "12          I-ORG         O      4\n",
      "13       I-PERSON     B-PER      4\n",
      "\n",
      "Conclusions:\n",
      "Best performing system: spaCy\n",
      "Recommendations:\n",
      "1. Use ensemble approach combining both systems\n",
      "2. Add post-processing rules for specific domains\n",
      "3. Consider fine-tuning on domain-specific data\n",
      "\n",
      "Summary Table:\n",
      "  System  Accuracy  Error_Count\n",
      "0  spaCy    0.8380           35\n",
      "1   BERT    0.7454           55\n"
     ]
    }
   ],
   "source": [
    "# Detailed error analysis\n",
    "print(\"FINAL ANALYSIS & ERROR PATTERNS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Overall performance\n",
    "spacy_accuracy = comparison_df['spacy_correct'].mean()\n",
    "bert_accuracy = comparison_df['bert_correct'].mean()\n",
    "agreement_rate = comparison_df['systems_agree'].mean()\n",
    "\n",
    "print(f\"\\nOverall Performance:\")\n",
    "print(f\"spaCy accuracy: {spacy_accuracy:.4f}\")\n",
    "print(f\"BERT accuracy: {bert_accuracy:.4f}\")\n",
    "print(f\"System agreement: {agreement_rate:.4f}\")\n",
    "\n",
    "# Performance by entity type\n",
    "print(f\"\\nPerformance by Entity Type:\")\n",
    "for entity_type in ['PERSON', 'ORG', 'LOCATION', 'WORK_OF_ART', 'MISC']:\n",
    "    entity_mask = comparison_df['true_label'].str.contains(entity_type, na=False)\n",
    "    entity_tokens = comparison_df[entity_mask]\n",
    "    \n",
    "    if len(entity_tokens) > 0:\n",
    "        spacy_acc = entity_tokens['spacy_correct'].mean()\n",
    "        bert_acc = entity_tokens['bert_correct'].mean()\n",
    "        print(f\"{entity_type}: spaCy {spacy_acc:.3f}, BERT {bert_acc:.3f} ({len(entity_tokens)} tokens)\")\n",
    "\n",
    "# Error patterns\n",
    "spacy_errors = comparison_df[~comparison_df['spacy_correct']]\n",
    "bert_errors = comparison_df[~comparison_df['bert_correct']]\n",
    "\n",
    "print(f\"\\nError Summary:\")\n",
    "print(f\"spaCy errors: {len(spacy_errors)} tokens\")\n",
    "print(f\"BERT errors: {len(bert_errors)} tokens\")\n",
    "\n",
    "if len(spacy_errors) > 0:\n",
    "    print(\"\\nMost common spaCy error patterns:\")\n",
    "    spacy_error_patterns = spacy_errors.groupby(['true_label', 'spacy_pred']).size().reset_index(name='count')\n",
    "    print(spacy_error_patterns.sort_values('count', ascending=False).head())\n",
    "\n",
    "if len(bert_errors) > 0:\n",
    "    print(\"\\nMost common BERT error patterns:\")\n",
    "    bert_error_patterns = bert_errors.groupby(['true_label', 'bert_pred']).size().reset_index(name='count')\n",
    "    print(bert_error_patterns.sort_values('count', ascending=False).head())\n",
    "\n",
    "# Final recommendations\n",
    "better_system = \"spaCy\" if spacy_accuracy > bert_accuracy else \"BERT\"\n",
    "print(f\"\\nConclusions:\")\n",
    "print(f\"Best performing system: {better_system}\")\n",
    "print(f\"Recommendations:\")\n",
    "print(\"1. Use ensemble approach combining both systems\")\n",
    "print(\"2. Add post-processing rules for specific domains\")\n",
    "print(\"3. Consider fine-tuning on domain-specific data\")\n",
    "\n",
    "# Create summary table\n",
    "summary_data = {\n",
    "    'System': ['spaCy', 'BERT'],\n",
    "    'Accuracy': [spacy_accuracy, bert_accuracy],\n",
    "    'Error_Count': [len(spacy_errors), len(bert_errors)]\n",
    "}\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(f\"\\nSummary Table:\")\n",
    "print(summary_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f084d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
